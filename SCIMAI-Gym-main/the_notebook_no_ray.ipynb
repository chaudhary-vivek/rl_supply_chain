{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Info\n",
    ">**TITLE:** *SCIMAI-Gym (No Ray Version)*  \n",
    "\n",
    "**AUTHORS:** *Francesco Stranieri*  \n",
    "\n",
    "**INSTITUTION:** *University of Milano-Bicocca/Polytechnic of Turin*  \n",
    "\n",
    "**EMAIL:** *francesco.stranieri@unimib.it*\n",
    "[The MIT License (MIT)](https://github.com/frenkowski/SCIMAI-Gym/blob/main/LICENSE)\n",
    "\n",
    "\n",
    "\n",
    "Copyright (c) 2023 Francesco Stranieri\n",
    "Code inspired by hands-on tutorial ['Deep reinforcement learning for supply chain and price optimization'](https://blog.griddynamics.com/deep-reinforcement-learning-for-supply-chain-and-price-optimization/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required to use with Python >= 3.7\n",
    "import sys\n",
    "\n",
    "version_info = sys.version_info\n",
    "print(f\"Python version is {version_info}\")\n",
    "\n",
    "if sys.version_info >= (3, 7):\n",
    "    %pip uninstall -y dataclasses\n",
    "else:\n",
    "    %pip install -U dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install stable-baselines3 instead of Ray\n",
    "%pip install stable-baselines3[extra] gymnasium scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('LOGGING_SCIMAI-Gym_V1')\n",
    "logger.setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Gymnasium (successor to Gym)\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stable-baselines3 instead of Ray\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Ax for hyperparameter optimization\n",
    "from ax import optimize\n",
    "from ax.plot.contour import interact_contour\n",
    "from ax.plot.contour import plot_contour_plotly\n",
    "from ax.plot.trace import optimization_trace_single_method_plotly\n",
    "from ax.utils.notebook.plotting import render\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from tabulate import tabulate\n",
    "from timeit import default_timer\n",
    "from IPython.display import display\n",
    "\n",
    "import collections\n",
    "import dataframe_image as dfi\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed for reproducibility\n",
    "seed = 2021\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting output views only in case of debug\n",
    "if logger.level == 10:\n",
    "    verbose = 3\n",
    "    plt.ion()\n",
    "else:\n",
    "    verbose = 0\n",
    "    plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of CPUs\n",
    "import multiprocessing\n",
    "\n",
    "try:\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")\n",
    "    num_cpus = 0\n",
    "\n",
    "print(f\"num cpus is {num_cpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of GPUs\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "    else:\n",
    "        num_gpus = 0\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")\n",
    "    num_gpus = 0\n",
    "\n",
    "print(f\"num gpus is {num_gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\"\n",
    "    We choose the state vector to include all current stock levels for each \n",
    "    warehouse and product type, plus the last demand values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, product_types_num, distr_warehouses_num, T,\n",
    "                 demand_history, t=0):\n",
    "        self.product_types_num = product_types_num\n",
    "        self.factory_stocks = np.zeros(\n",
    "            (self.product_types_num,),\n",
    "            dtype=np.int32)\n",
    "        self.distr_warehouses_num = distr_warehouses_num\n",
    "        self.distr_warehouses_stocks = np.zeros(\n",
    "            (self.distr_warehouses_num, self.product_types_num),\n",
    "            dtype=np.int32)\n",
    "        self.T = T\n",
    "        self.demand_history = demand_history\n",
    "        self.t = t\n",
    "\n",
    "        logger.debug(f\"\\n--- State --- __init__\"\n",
    "                     f\"\\nproduct_types_num is \"\n",
    "                     f\"{self.product_types_num}\"\n",
    "                     f\"\\nfactory_stocks is \"\n",
    "                     f\"{self.factory_stocks}\"\n",
    "                     f\"\\ndistr_warehouses_num is \"\n",
    "                     f\"{self.distr_warehouses_num}\"\n",
    "                     f\"\\ndistr_warehouses_stocks is \"\n",
    "                     f\"{self.distr_warehouses_stocks}\"\n",
    "                     f\"\\nT is \"\n",
    "                     f\"{self.T}\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "    def to_array(self):\n",
    "        logger.debug(f\"\\n--- State --- to_array\"\n",
    "                     f\"\\nnp.concatenate is \"\n",
    "                     f\"\"\"{np.concatenate((\n",
    "                         self.factory_stocks,\n",
    "                         self.distr_warehouses_stocks.flatten(),\n",
    "                         np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "                         [self.t]))}\"\"\")\n",
    "\n",
    "        return np.concatenate((\n",
    "            self.factory_stocks,\n",
    "            self.distr_warehouses_stocks.flatten(),\n",
    "            np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "            [self.t]))\n",
    "\n",
    "    def stock_levels(self):\n",
    "        logger.debug(f\"\\n--- State --- stock_levels\"\n",
    "                     f\"\\nnp.concatenate is \"\n",
    "                     f\"\"\"{np.concatenate((\n",
    "                         self.factory_stocks,\n",
    "                         self.distr_warehouses_stocks.flatten()))}\"\"\")\n",
    "\n",
    "        return np.concatenate((\n",
    "            self.factory_stocks,\n",
    "            self.distr_warehouses_stocks.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \"\"\"\n",
    "    The action vector consists of production and shipping controls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, product_types_num, distr_warehouses_num):\n",
    "        self.production_level = np.zeros(\n",
    "            (product_types_num,),\n",
    "            dtype=np.int32)\n",
    "        self.shipped_stocks = np.zeros(\n",
    "            (distr_warehouses_num, product_types_num),\n",
    "            dtype=np.int32)\n",
    "\n",
    "        logger.debug(f\"\\n--- Action --- __init__\"\n",
    "                     f\"\\nproduction_level is \"\n",
    "                     f\"{self.production_level}\"\n",
    "                     f\"\\nshipped_stocks is \"\n",
    "                     f\"{self.shipped_stocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply Chain Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupplyChainEnvironment:\n",
    "    \"\"\"\n",
    "    We designed a divergent two-echelon supply chain that includes a single \n",
    "    factory, multiple distribution warehouses, and multiple product types over \n",
    "    a fixed number of time steps. At each time step, the agent is asked to find \n",
    "    the number of products to be produced and preserved at the factory, as well \n",
    "    as the number of products to be shipped to different distribution \n",
    "    warehouses. To make the supply chain more realistic, we set capacity \n",
    "    constraints on warehouses (and consequently, on how many units to produce \n",
    "    at the factory), along with storage and transportation costs. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # number of product types (e.g., 2 product types)\n",
    "        self.product_types_num = 2\n",
    "        # number of distribution warehouses (e.g., 2 distribution warehouses)\n",
    "        self.distr_warehouses_num = 2\n",
    "        # final time step (e.g., an episode takes 25 time steps)\n",
    "        self.T = 25\n",
    "\n",
    "        # maximum demand value, units (e.g., [3, 6])\n",
    "        self.d_max = np.array(\n",
    "            [3, 6],\n",
    "            np.int32)\n",
    "        # maximum demand variation according to a uniform distribution,\n",
    "        # units (e.g., [2, 1])\n",
    "        self.d_var = np.array(\n",
    "            [2, 1],\n",
    "            np.int32)\n",
    "\n",
    "        # sale prices, per unit (e.g., [20, 10])\n",
    "        self.sale_prices = np.array(\n",
    "            [20, 10],\n",
    "            np.int32)\n",
    "        # production costs, per unit (e.g., [2, 1])\n",
    "        self.production_costs = np.array(\n",
    "            [2, 1],\n",
    "            np.int32)\n",
    "\n",
    "        # storage capacities for each product type at each warehouse,\n",
    "        # units (e.g., [[3, 4], [6, 8], [9, 12]])\n",
    "        self.storage_capacities = np.array(\n",
    "            [[3, 4], [6, 8], [9, 12]],\n",
    "            np.int32)\n",
    "\n",
    "        # storage costs of each product type at each warehouse,\n",
    "        # per unit (e.g., [[6, 3], [4, 2], [2, 1]])\n",
    "        self.storage_costs = np.array(\n",
    "            [[6, 3], [4, 2], [2, 1]],\n",
    "            np.float32)\n",
    "        # transportation costs of each product type for each distribution\n",
    "        # warehouse, per unit (e.g., [[.1, .3], [.2, .6]])\n",
    "        self.transportation_costs = np.array(\n",
    "            [[.1, .3], [.2, .6]],\n",
    "            np.float32)\n",
    "\n",
    "        # penalty costs, per unit (e.g., [10, 5])\n",
    "        self.penalty_costs = .5*self.sale_prices\n",
    "\n",
    "        print(f\"\\n--- SupplyChainEnvironment --- __init__\"\n",
    "              f\"\\nproduct_types_num is \"\n",
    "              f\"{self.product_types_num}\"\n",
    "              f\"\\ndistr_warehouses_num is \"\n",
    "              f\"{self.distr_warehouses_num}\"\n",
    "              f\"\\nT is \"\n",
    "              f\"{self.T}\"\n",
    "              f\"\\nd_max is \"\n",
    "              f\"{self.d_max}\"\n",
    "              f\"\\nd_var is \"\n",
    "              f\"{self.d_var}\"\n",
    "              f\"\\nsale_prices is \"\n",
    "              f\"{self.sale_prices}\"\n",
    "              f\"\\nproduction_costs is \"\n",
    "              f\"{self.production_costs}\"\n",
    "              f\"\\nstorage_capacities is \"\n",
    "              f\"{self.storage_capacities}\"\n",
    "              f\"\\nstorage_costs is \"\n",
    "              f\"{self.storage_costs}\"\n",
    "              f\"\\ntransportation_costs is \"\n",
    "              f\"{self.transportation_costs}\"\n",
    "              f\"\\npenalty_costs is \"\n",
    "              f\"{self.penalty_costs}\")\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, demand_history_len=5):\n",
    "        # (five) demand values observed\n",
    "        self.demand_history = collections.deque(maxlen=demand_history_len)\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- reset\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\")\n",
    "\n",
    "        for d in range(demand_history_len):\n",
    "            self.demand_history.append(np.zeros(\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32))\n",
    "        self.t = 0\n",
    "\n",
    "        logger.debug(f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "    def demand(self, j, i, t):\n",
    "        # we simulate a seasonal behavior by representing the demand as a\n",
    "        # co-sinusoidal function with a stochastic component (a random variable\n",
    "        # assumed to be distributed according to a uniform distribution),\n",
    "        # in order to evaluate the agent\n",
    "        demand = np.round(\n",
    "            self.d_max[i-1]/2 +\n",
    "            self.d_max[i-1]/2*np.cos(4*np.pi*(2*j*i+t)/self.T) +\n",
    "            np.random.randint(0, self.d_var[i-1]+1))\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- demand\"\n",
    "                     f\"\\nj is \"\n",
    "                     f\"{j}\"\n",
    "                     f\"\\ni is \"\n",
    "                     f\"{i}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\ndemand is \"\n",
    "                     f\"{demand}\")\n",
    "\n",
    "        return demand\n",
    "\n",
    "    def initial_state(self):\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- initial_state\"\n",
    "                     f\"\\nState is \"\n",
    "                     f\"\"\"{State(\n",
    "                         self.product_types_num, self.distr_warehouses_num, \n",
    "                         self.T, list(self.demand_history))}\"\"\")\n",
    "\n",
    "        return State(self.product_types_num, self.distr_warehouses_num,\n",
    "                     self.T, list(self.demand_history))\n",
    "\n",
    "    def step(self, state, action):\n",
    "        demands = np.fromfunction(\n",
    "            lambda j, i: self.demand(j+1, i+1, self.t),\n",
    "            (self.distr_warehouses_num, self.product_types_num),\n",
    "            dtype=np.int32)\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- step\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\ndemands is \"\n",
    "                     f\"{demands}\")\n",
    "\n",
    "        # next state\n",
    "        next_state = State(self.product_types_num, self.distr_warehouses_num,\n",
    "                           self.T, list(self.demand_history))\n",
    "\n",
    "        next_state.factory_stocks = np.minimum(\n",
    "            np.subtract(np.add(state.factory_stocks,\n",
    "                               action.production_level),\n",
    "                        np.sum(action.shipped_stocks, axis=0)\n",
    "                        ),\n",
    "            self.storage_capacities[0]\n",
    "        )\n",
    "\n",
    "        for j in range(self.distr_warehouses_num):\n",
    "            next_state.distr_warehouses_stocks[j] = np.minimum(\n",
    "                np.subtract(np.add(state.distr_warehouses_stocks[j],\n",
    "                                   action.shipped_stocks[j]),\n",
    "                            demands[j]\n",
    "                            ),\n",
    "                self.storage_capacities[j+1]\n",
    "            )\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- next state\"\n",
    "                     f\"\\nnext_state is \"\n",
    "                     f\"{next_state}\"\n",
    "                     f\"\\nnext_state.factory_stocks is \"\n",
    "                     f\"{next_state.factory_stocks}\"\n",
    "                     f\"\\nnext_state.distr_warehouses_stocks is \"\n",
    "                     f\"{next_state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nnext_state.demand_history is \"\n",
    "                     f\"{next_state.demand_history}\"\n",
    "                     f\"\\nnext_state.t is \"\n",
    "                     f\"{next_state.t}\")\n",
    "\n",
    "        # revenues\n",
    "        total_revenues = np.dot(self.sale_prices,\n",
    "                                np.sum(demands, axis=0))\n",
    "        # production costs\n",
    "        total_production_costs = np.dot(self.production_costs,\n",
    "                                        action.production_level)\n",
    "        # transportation costs\n",
    "        total_transportation_costs = np.dot(\n",
    "            self.transportation_costs.flatten(),\n",
    "            action.shipped_stocks.flatten())\n",
    "        # storage costs\n",
    "        total_storage_costs = np.dot(\n",
    "            self.storage_costs.flatten(),\n",
    "            np.maximum(next_state.stock_levels(),\n",
    "                       np.zeros(\n",
    "                           ((self.distr_warehouses_num+1) *\n",
    "                            self.product_types_num),\n",
    "                           dtype=np.int32)\n",
    "                       )\n",
    "        )\n",
    "        # penalty costs (minus sign because stock levels would be already\n",
    "        # negative in case of unfulfilled demand)\n",
    "        total_penalty_costs = -np.dot(\n",
    "            self.penalty_costs,\n",
    "            np.add(\n",
    "                np.sum(\n",
    "                    np.minimum(next_state.distr_warehouses_stocks,\n",
    "                               np.zeros(\n",
    "                                   (self.distr_warehouses_num,\n",
    "                                    self.product_types_num),\n",
    "                                   dtype=np.int32)\n",
    "                               ),\n",
    "                    axis=0),\n",
    "                np.minimum(next_state.factory_stocks,\n",
    "                           np.zeros(\n",
    "                               (self.product_types_num,),\n",
    "                               dtype=np.int32)\n",
    "                           )\n",
    "            )\n",
    "        )\n",
    "        # reward function\n",
    "        reward = total_revenues - total_production_costs - \\\n",
    "            total_transportation_costs - total_storage_costs - \\\n",
    "            total_penalty_costs\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- reward\"\n",
    "                     f\"\\ntotal_revenues is \"\n",
    "                     f\"{total_revenues}\"\n",
    "                     f\"\\ntotal_production_costs is \"\n",
    "                     f\"{total_production_costs}\"\n",
    "                     f\"\\ntotal_transportation_costs is \"\n",
    "                     f\"{total_transportation_costs}\"\n",
    "                     f\"\\ntotal_storage_costs is \"\n",
    "                     f\"{total_storage_costs}\"\n",
    "                     f\"\\ntotal_penalty_costs is \"\n",
    "                     f\"{total_penalty_costs}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "        # the actual demand for the current time step will not be known until\n",
    "        # the next time step. This implementation choice ensures that the agent\n",
    "        # may benefit from learning the demand pattern so as to integrate a\n",
    "        # sort of demand forecasting directly into the policy\n",
    "        self.demand_history.append(demands)\n",
    "        # actual time step value is not observed (for now)\n",
    "        self.t += 1\n",
    "\n",
    "        logger.debug(f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- return\"\n",
    "                     f\"\\nnext_state is \"\n",
    "                     f\"{next_state}, \"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}, \"\n",
    "                     f\"\\ndone is \"\n",
    "                     f\"{self.t == self.T-1}\")\n",
    "\n",
    "        return next_state, reward, self.t == self.T-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply Chain Gym Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupplyChain(gym.Env):\n",
    "    \"\"\"\n",
    "    Gymnasium environment wrapper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\
